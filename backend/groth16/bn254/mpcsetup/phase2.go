// Copyright 2020 ConsenSys Software Inc.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Code generated by gnark DO NOT EDIT

package mpcsetup

import (
	"crypto/sha256"
	"errors"
	"github.com/consensys/gnark-crypto/ecc/bn254/fr/pedersen"
	"github.com/consensys/gnark/backend/groth16/internal"
	"math/big"
	"slices"

	curve "github.com/consensys/gnark-crypto/ecc/bn254"
	"github.com/consensys/gnark-crypto/ecc/bn254/fr"
	"github.com/consensys/gnark/constraint"
	cs "github.com/consensys/gnark/constraint/bn254"
)

type Phase2Evaluations struct {
	G1 struct {
		A   []curve.G1Affine // A are the left coefficient polynomials for each witness element, evaluated at Ï„
		B   []curve.G1Affine // B are the right coefficient polynomials for each witness element, evaluated at Ï„
		VKK []curve.G1Affine // VKK are the coefficients of the public witness (and commitments)
	}
	G2 struct {
		B []curve.G2Affine // B are the right coefficient polynomials for each witness element, evaluated at Ï„
	}
}

type Phase2 struct {
	Parameters struct {
		G1 struct {
			Delta curve.G1Affine
			Z     []curve.G1Affine // Z is the domain vanishing polynomial
			PKK   []curve.G1Affine // PKK are the coefficients of the private witness
		}
		G2 struct {
			Delta curve.G2Affine
			Sigma curve.G2Affine
		}
		CommitmentKeys []pedersen.ProvingKey
	}
	Sigmas []valueUpdate // commitment key secrets
	Delta  valueUpdate   // updates to delta
	Hash   []byte
}

// Init is to be run by the coordinator
// It involves no coin tosses. A verifier should
// simply rerun all the steps
func (p *Phase2) Init(commons SrsCommons) {

}

func InitPhase2(r1cs *cs.R1CS, srs1 *Phase1) (Phase2, Phase2Evaluations) {

	srs := srs1.parameters
	size := len(srs.G1.AlphaTau)
	if size < r1cs.GetNbConstraints() {
		panic("Number of constraints is larger than expected")
	}

	var c2 Phase2

	accumulateG1 := func(res *curve.G1Affine, t constraint.Term, value *curve.G1Affine) {
		cID := t.CoeffID()
		switch cID {
		case constraint.CoeffIdZero:
			return
		case constraint.CoeffIdOne:
			res.Add(res, value)
		case constraint.CoeffIdMinusOne:
			res.Sub(res, value)
		case constraint.CoeffIdTwo:
			res.Add(res, value).Add(res, value)
		default:
			var tmp curve.G1Affine
			var vBi big.Int
			r1cs.Coefficients[cID].BigInt(&vBi)
			tmp.ScalarMultiplication(value, &vBi)
			res.Add(res, &tmp)
		}
	}

	accumulateG2 := func(res *curve.G2Affine, t constraint.Term, value *curve.G2Affine) {
		cID := t.CoeffID()
		switch cID {
		case constraint.CoeffIdZero:
			return
		case constraint.CoeffIdOne:
			res.Add(res, value)
		case constraint.CoeffIdMinusOne:
			res.Sub(res, value)
		case constraint.CoeffIdTwo:
			res.Add(res, value).Add(res, value)
		default:
			var tmp curve.G2Affine
			var vBi big.Int
			r1cs.Coefficients[cID].BigInt(&vBi)
			tmp.ScalarMultiplication(value, &vBi)
			res.Add(res, &tmp)
		}
	}

	// Prepare Lagrange coefficients of [Ï„...]â‚, [Ï„...]â‚‚, [Î±Ï„...]â‚, [Î²Ï„...]â‚
	coeffTau1 := lagrangeCoeffsG1(srs.G1.Tau, size)           // [L_{Ï‰â°}(Ï„)]â‚, [L_{Ï‰Â¹}(Ï„)]â‚, ... where Ï‰ is a primitive sizeáµ—Ê° root of unity
	coeffTau2 := lagrangeCoeffsG2(srs.G2.Tau, size)           // [L_{Ï‰â°}(Ï„)]â‚‚, [L_{Ï‰Â¹}(Ï„)]â‚‚, ...
	coeffAlphaTau1 := lagrangeCoeffsG1(srs.G1.AlphaTau, size) // [L_{Ï‰â°}(Î±Ï„)]â‚, [L_{Ï‰Â¹}(Î±Ï„)]â‚, ...
	coeffBetaTau1 := lagrangeCoeffsG1(srs.G1.BetaTau, size)   // [L_{Ï‰â°}(Î²Ï„)]â‚, [L_{Ï‰Â¹}(Î²Ï„)]â‚, ...

	nbInternal, nbSecret, nbPublic := r1cs.GetNbVariables()
	nWires := nbInternal + nbSecret + nbPublic
	var evals Phase2Evaluations
	evals.G1.A = make([]curve.G1Affine, nWires) // recall: A are the left coefficients in DIZK parlance
	evals.G1.B = make([]curve.G1Affine, nWires) // recall: B are the right coefficients in DIZK parlance
	evals.G2.B = make([]curve.G2Affine, nWires) // recall: A only appears in ð”¾â‚ elements in the proof, but B needs to appear in a ð”¾â‚‚ element so the verifier can compute something resembling (A.x).(B.x) via pairings
	bA := make([]curve.G1Affine, nWires)
	aB := make([]curve.G1Affine, nWires)
	C := make([]curve.G1Affine, nWires)

	i := 0
	it := r1cs.GetR1CIterator()
	for c := it.Next(); c != nil; c = it.Next() {
		// each constraint is sparse, i.e. involves a small portion of all variables.
		// so we iterate over the variables involved and add the constraint's contribution
		// to every variable's A, B, and C values

		// A
		for _, t := range c.L {
			accumulateG1(&evals.G1.A[t.WireID()], t, &coeffTau1[i])
			accumulateG1(&bA[t.WireID()], t, &coeffBetaTau1[i])
		}
		// B
		for _, t := range c.R {
			accumulateG1(&evals.G1.B[t.WireID()], t, &coeffTau1[i])
			accumulateG2(&evals.G2.B[t.WireID()], t, &coeffTau2[i])
			accumulateG1(&aB[t.WireID()], t, &coeffAlphaTau1[i])
		}
		// C
		for _, t := range c.O {
			accumulateG1(&C[t.WireID()], t, &coeffTau1[i])
		}
		i++
	}

	// Prepare default contribution
	_, _, g1, g2 := curve.Generators()
	c2.Parameters.G1.Delta = g1
	c2.Parameters.G2.Delta = g2
	c2.Parameters.G2.Sigma = g2

	// Build Z in PK as Ï„â±(Ï„â¿ - 1)  = Ï„â½â±âºâ¿â¾ - Ï„â±  for i âˆˆ [0, n-2]
	// Ï„â±(Ï„â¿ - 1)  = Ï„â½â±âºâ¿â¾ - Ï„â±  for i âˆˆ [0, n-2]
	n := len(srs.G1.AlphaTau)
	c2.Parameters.G1.Z = make([]curve.G1Affine, n)
	for i := 0; i < n-1; i++ {
		c2.Parameters.G1.Z[i].Sub(&srs.G1.Tau[i+n], &srs.G1.Tau[i])
	}
	bitReverse(c2.Parameters.G1.Z)
	c2.Parameters.G1.Z = c2.Parameters.G1.Z[:n-1]

	commitments := r1cs.CommitmentInfo.(constraint.Groth16Commitments)
	c2.Sigmas = make([]valueUpdate, len(commitments))
	c2.Parameters.CommitmentKeys = make([]pedersen.ProvingKey, len(commitments))
	for j := range commitments {
		c2.Parameters.CommitmentKeys[i].Basis = make([]curve.G1Affine, 0, len(commitments[j].PrivateCommitted))
	}
	nbCommitted := internal.NbElements(commitments.GetPrivateCommitted())

	// Evaluate PKK

	c2.Parameters.G1.PKK = make([]curve.G1Affine, 0, nbInternal+nbSecret-nbCommitted-len(commitments))
	evals.G1.VKK = make([]curve.G1Affine, 0, nbPublic+len(commitments))
	committedIterator := internal.NewMergeIterator(commitments.GetPrivateCommitted())
	nbCommitmentsSeen := 0
	for i := 0; i < nWires; i++ {
		// since as yet Î´, Î³ = 1, the VKK and PKK are computed identically, as Î²A + Î±B + C
		var tmp curve.G1Affine
		tmp.Add(&bA[i], &aB[i])
		tmp.Add(&tmp, &C[i])
		commitmentIndex := committedIterator.IndexIfNext(i)
		isCommitment := nbCommitmentsSeen < len(commitments) && commitments[nbCommitmentsSeen].CommitmentIndex == i
		if commitmentIndex != -1 {
			c2.Parameters.CommitmentKeys[commitmentIndex].Basis = append(c2.Parameters.CommitmentKeys[commitmentIndex].Basis, tmp)
		} else if i < nbPublic || isCommitment {
			evals.G1.VKK = append(evals.G1.VKK, tmp)
		} else {
			c2.Parameters.G1.PKK = append(c2.Parameters.G1.PKK, tmp)
		}
		if isCommitment {
			nbCommitmentsSeen++
		}
	}

	for i := range commitments {
		c2.Parameters.CommitmentKeys[i].BasisExpSigma = slices.Clone(c2.Parameters.CommitmentKeys[i].Basis)
	}

	// Hash initial contribution
	c2.Hash = c2.hash() // TODO remove
	return c2, evals
}

func (c *Phase2) Contribute() {
	// Sample toxic Î´
	var delta, deltaInv fr.Element
	var sigma fr.Element
	var deltaBI, deltaInvBI big.Int

	updateValue()

	delta.SetRandom()
	deltaInv.Inverse(&delta)

	delta.BigInt(&deltaBI)
	deltaInv.BigInt(&deltaInvBI)

	// Set Î´ public key
	c.PublicKey = newPublicKey(delta, c.Hash, 1)

	// Update Î´
	c.Parameters.G1.Delta.ScalarMultiplication(&c.Parameters.G1.Delta, &deltaBI)
	c.Parameters.G2.Delta.ScalarMultiplication(&c.Parameters.G2.Delta, &deltaBI)

	// Update Z using Î´â»Â¹
	for i := 0; i < len(c.Parameters.G1.Z); i++ {
		c.Parameters.G1.Z[i].ScalarMultiplication(&c.Parameters.G1.Z[i], &deltaInvBI)
	}

	// Update PKK using Î´â»Â¹
	for i := 0; i < len(c.Parameters.G1.PKK); i++ {
		c.Parameters.G1.PKK[i].ScalarMultiplication(&c.Parameters.G1.PKK[i], &deltaInvBI)
	}

	// 4. Hash contribution
	c.Hash = c.hash()
}

func VerifyPhase2(c0, c1 *Phase2, c ...*Phase2) error {
	contribs := append([]*Phase2{c0, c1}, c...)
	for i := 0; i < len(contribs)-1; i++ {
		if err := verifyPhase2(contribs[i], contribs[i+1]); err != nil {
			return err
		}
	}
	return nil
}

func verifyPhase2(current, contribution *Phase2) error {
	// Compute R for Î´
	deltaR := genR(contribution.PublicKey.SG, contribution.PublicKey.SXG, current.Hash[:], 1)

	// Check for knowledge of Î´
	if !sameRatio(contribution.PublicKey.SG, contribution.PublicKey.SXG, contribution.PublicKey.XR, deltaR) {
		return errors.New("couldn't verify knowledge of Î´")
	}

	// Check for valid updates using previous parameters
	if !sameRatio(contribution.Parameters.G1.Delta, current.Parameters.G1.Delta, deltaR, contribution.PublicKey.XR) {
		return errors.New("couldn't verify that [Î´]â‚ is based on previous contribution")
	}
	if !sameRatio(contribution.PublicKey.SG, contribution.PublicKey.SXG, contribution.Parameters.G2.Delta, current.Parameters.G2.Delta) {
		return errors.New("couldn't verify that [Î´]â‚‚ is based on previous contribution")
	}

	// Check for valid updates of PKK and Z using
	L, prevL := merge(contribution.Parameters.G1.PKK, current.Parameters.G1.PKK)
	if !sameRatio(L, prevL, contribution.Parameters.G2.Delta, current.Parameters.G2.Delta) {
		return errors.New("couldn't verify valid updates of PKK using Î´â»Â¹")
	}
	Z, prevZ := merge(contribution.Parameters.G1.Z, current.Parameters.G1.Z)
	if !sameRatio(Z, prevZ, contribution.Parameters.G2.Delta, current.Parameters.G2.Delta) {
		return errors.New("couldn't verify valid updates of PKK using Î´â»Â¹")
	}

	// Check hash of the contribution
	h := contribution.hash()
	for i := 0; i < len(h); i++ {
		if h[i] != contribution.Hash[i] {
			return errors.New("couldn't verify hash of contribution")
		}
	}

	return nil
}

func (c *Phase2) hash() []byte {
	sha := sha256.New()
	c.writeTo(sha)
	return sha.Sum(nil)
}
