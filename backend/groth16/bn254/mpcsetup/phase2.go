// Copyright 2020-2024 Consensys Software Inc.
// Licensed under the Apache License, Version 2.0. See the LICENSE file for details.

// Code generated by gnark DO NOT EDIT

package mpcsetup

import (
	"bytes"
	"crypto/sha256"
	"errors"
	"fmt"
	"github.com/consensys/gnark/backend/groth16"
	"github.com/consensys/gnark/backend/groth16/internal"
	cs "github.com/consensys/gnark/constraint/bn254"
	"math/big"
	"slices"

	curve "github.com/consensys/gnark-crypto/ecc/bn254"
	"github.com/consensys/gnark-crypto/ecc/bn254/fr"
	"github.com/consensys/gnark/constraint"
)

// Phase2Evaluations components of the circuit keys
// not depending on Phase2 randomisations
type Phase2Evaluations struct { // TODO @Tabaie rename
	G1 struct {
		A   []curve.G1Affine   // A are the left coefficient polynomials for each witness element, evaluated at Ï„
		B   []curve.G1Affine   // B are the right coefficient polynomials for each witness element, evaluated at Ï„
		VKK []curve.G1Affine   // VKK are the coefficients of the public witness and commitments
		CKK [][]curve.G1Affine // CKK are the coefficients of the committed values
	}
	G2 struct {
		B []curve.G2Affine // B are the right coefficient polynomials for each witness element, evaluated at Ï„
	}
	PublicAndCommitmentCommitted [][]int
	NbConstraints                uint64
}

type Phase2 struct {
	Parameters struct {
		G1 struct {
			Delta    curve.G1Affine
			Z        []curve.G1Affine   // Z[i] = xâ±t(x)/Î´ where t is the domain vanishing polynomial 0 â‰¤ i â‰¤ N-2
			PKK      []curve.G1Affine   // PKK are the coefficients of the private witness, needed for the proving key. They have a denominator of Î´
			SigmaCKK [][]curve.G1Affine // Commitment proof bases: SigmaCKK[i][j] = Cáµ¢â±¼Ïƒáµ¢ where Cáµ¢â±¼ is the commitment basis for the jáµ—Ê° committed element from the iáµ—Ê° commitment
		}
		G2 struct {
			Delta curve.G2Affine
			Sigma []curve.G2Affine // the secret Ïƒ value for each commitment
		}
	}

	// Proofs of update correctness
	Sigmas []valueUpdate
	Delta  valueUpdate

	// Challenge is the hash of the PREVIOUS contribution
	Challenge []byte
}

func (p *Phase2) Verify(next *Phase2) error {
	challenge := p.hash()
	if len(next.Challenge) != 0 && !bytes.Equal(next.Challenge, challenge) {
		return errors.New("the challenge does not match the previous phase's hash")
	}
	next.Challenge = challenge

	if len(next.Parameters.G1.Z) != len(p.Parameters.G1.Z) ||
		len(next.Parameters.G1.PKK) != len(p.Parameters.G1.PKK) ||
		len(next.Parameters.G1.SigmaCKK) != len(p.Parameters.G1.SigmaCKK) ||
		len(next.Parameters.G2.Sigma) != len(p.Parameters.G2.Sigma) {
		return errors.New("contribution size mismatch")
	}

	r := linearCombCoeffs(len(next.Parameters.G1.Z) + len(next.Parameters.G1.PKK) + 1) // TODO @Tabaie If all contributions are being verified in one go, we could reuse r

	verifyContribution := func(update *valueUpdate, g1Denominator, g1Numerator []curve.G1Affine, g2Denominator, g2Numerator *curve.G2Affine, dst byte) error {
		g1Num := linearCombination(g1Numerator, r)
		g1Denom := linearCombination(g1Denominator, r)

		return update.verify(pair{g1Denom, g2Denominator}, pair{g1Num, g2Denominator}, challenge, dst)
	}

	// verify proof of knowledge of contributions to the Ïƒáµ¢
	// and the correctness of updates to Parameters.G2.Sigma[i] and the Parameters.G1.SigmaCKK[i]
	for i := range p.Sigmas { // match the first commitment basis elem against the contribution commitment
		if !areInSubGroupG1(next.Parameters.G1.SigmaCKK[i]) {
			return errors.New("commitment proving key subgroup check failed")
		}

		if err := verifyContribution(&p.Sigmas[i], p.Parameters.G1.SigmaCKK[i], next.Parameters.G1.SigmaCKK[i], &p.Parameters.G2.Sigma[i], &next.Parameters.G2.Sigma[i], 2+byte(i)); err != nil {
			return fmt.Errorf("failed to verify contribution to Ïƒ[%d]: %w", i, err)
		}
	}

	// verify proof of knowledge of contribution to Î´
	// and the correctness of updates to Parameters.Gi.Delta, PKK[i], and Z[i]
	if !areInSubGroupG1(next.Parameters.G1.Z) || !areInSubGroupG1(next.Parameters.G1.PKK) {
		return errors.New("derived values ð”¾â‚ subgroup check failed")
	}

	denom := cloneAppend([]curve.G1Affine{p.Parameters.G1.Delta}, next.Parameters.G1.Z, next.Parameters.G1.PKK)
	num := cloneAppend([]curve.G1Affine{next.Parameters.G1.Delta}, p.Parameters.G1.Z, p.Parameters.G1.PKK)
	if err := verifyContribution(&p.Delta, denom, num, &p.Parameters.G2.Delta, &next.Parameters.G2.Delta, 1); err != nil {
		return fmt.Errorf("failed to verify contribution to Î´: %w", err)
	}

	return nil
}

// update modifies delta
func (p *Phase2) update(delta *fr.Element, sigma []fr.Element) {
	var I big.Int

	scale := func(point any) {
		switch p := point.(type) {
		case *curve.G1Affine:
			p.ScalarMultiplication(p, &I)
		case *curve.G2Affine:
			p.ScalarMultiplication(p, &I)
		default:
			panic("unknown type")
		}
	}

	for i := range sigma {
		sigma[i].BigInt(&I)
		s := p.Parameters.G1.SigmaCKK[i]
		for j := range s {
			scale(&s[j])
		}
		point := &p.Parameters.G2.Sigma[i]
		point.ScalarMultiplicationBase(&I)
	}

	delta.BigInt(&I)
	scale(&p.Parameters.G2.Delta)
	scale(&p.Parameters.G1.Delta)

	delta.Inverse(delta)
	delta.BigInt(&I)
	for i := range p.Parameters.G1.Z {
		scale(&p.Parameters.G1.Z[i])
	}
	for i := range p.Parameters.G1.PKK {
		scale(&p.Parameters.G1.PKK[i])
	}
}

func (p *Phase2) Contribute() {
	p.Challenge = p.hash()

	// sample value contributions and provide correctness proofs
	var delta fr.Element
	p.Delta, delta = updateValue(p.Parameters.G1.Delta, p.Challenge, 1)

	sigma := make([]fr.Element, len(p.Parameters.G1.SigmaCKK))
	if len(sigma) > 255 {
		panic("too many commitments") // DST collision
	}
	for i := range sigma {
		p.Sigmas[i], sigma[i] = updateValue(p.Parameters.G1.SigmaCKK[i][0], p.Challenge, byte(2+i))
	}

	p.update(&delta, sigma)
}

// Initialize is to be run by the coordinator
// It involves no coin tosses. A verifier should
// simply rerun all the steps
func (p *Phase2) Initialize(r1cs *cs.R1CS, commons *SrsCommons) Phase2Evaluations {

	size := len(commons.G1.AlphaTau)
	if size < r1cs.GetNbConstraints() {
		panic("Number of constraints is larger than expected")
	}

	accumulateG1 := func(res *curve.G1Affine, t constraint.Term, value *curve.G1Affine) {
		cID := t.CoeffID()
		switch cID {
		case constraint.CoeffIdZero:
			return
		case constraint.CoeffIdOne:
			res.Add(res, value)
		case constraint.CoeffIdMinusOne:
			res.Sub(res, value)
		case constraint.CoeffIdTwo:
			res.Add(res, value).Add(res, value)
		default:
			var tmp curve.G1Affine
			var vBi big.Int
			r1cs.Coefficients[cID].BigInt(&vBi)
			tmp.ScalarMultiplication(value, &vBi)
			res.Add(res, &tmp)
		}
	}

	accumulateG2 := func(res *curve.G2Affine, t constraint.Term, value *curve.G2Affine) {
		cID := t.CoeffID()
		switch cID {
		case constraint.CoeffIdZero:
			return
		case constraint.CoeffIdOne:
			res.Add(res, value)
		case constraint.CoeffIdMinusOne:
			res.Sub(res, value)
		case constraint.CoeffIdTwo:
			res.Add(res, value).Add(res, value)
		default:
			var tmp curve.G2Affine
			var vBi big.Int
			r1cs.Coefficients[cID].BigInt(&vBi)
			tmp.ScalarMultiplication(value, &vBi)
			res.Add(res, &tmp)
		}
	}

	// Prepare Lagrange coefficients of [Ï„...]â‚, [Ï„...]â‚‚, [Î±Ï„...]â‚, [Î²Ï„...]â‚
	coeffTau1 := lagrangeCoeffsG1(commons.G1.Tau, size)           // [L_{Ï‰â°}(Ï„)]â‚, [L_{Ï‰Â¹}(Ï„)]â‚, ... where Ï‰ is a primitive sizeáµ—Ê° root of unity
	coeffTau2 := lagrangeCoeffsG2(commons.G2.Tau, size)           // [L_{Ï‰â°}(Ï„)]â‚‚, [L_{Ï‰Â¹}(Ï„)]â‚‚, ...
	coeffAlphaTau1 := lagrangeCoeffsG1(commons.G1.AlphaTau, size) // [L_{Ï‰â°}(Î±Ï„)]â‚, [L_{Ï‰Â¹}(Î±Ï„)]â‚, ...
	coeffBetaTau1 := lagrangeCoeffsG1(commons.G1.BetaTau, size)   // [L_{Ï‰â°}(Î²Ï„)]â‚, [L_{Ï‰Â¹}(Î²Ï„)]â‚, ...

	nbInternal, nbSecret, nbPublic := r1cs.GetNbVariables()
	nWires := nbInternal + nbSecret + nbPublic
	var evals Phase2Evaluations
	commitmentInfo := r1cs.CommitmentInfo.(constraint.Groth16Commitments)
	evals.PublicAndCommitmentCommitted = commitmentInfo.GetPublicAndCommitmentCommitted(commitmentInfo.CommitmentIndexes(), nbPublic)
	evals.NbConstraints = uint64(r1cs.GetNbConstraints())
	evals.G1.A = make([]curve.G1Affine, nWires) // recall: A are the left coefficients in DIZK parlance
	evals.G1.B = make([]curve.G1Affine, nWires) // recall: B are the right coefficients in DIZK parlance
	evals.G2.B = make([]curve.G2Affine, nWires) // recall: A only appears in ð”¾â‚ elements in the proof, but B needs to appear in a ð”¾â‚‚ element so the verifier can compute something resembling (A.x).(B.x) via pairings
	bA := make([]curve.G1Affine, nWires)
	aB := make([]curve.G1Affine, nWires)
	C := make([]curve.G1Affine, nWires)

	i := 0
	it := r1cs.GetR1CIterator()
	for c := it.Next(); c != nil; c = it.Next() {
		// each constraint is sparse, i.e. involves a small portion of all variables.
		// so we iterate over the variables involved and add the constraint's contribution
		// to every variable's A, B, and C values

		// A
		for _, t := range c.L {
			accumulateG1(&evals.G1.A[t.WireID()], t, &coeffTau1[i])
			accumulateG1(&bA[t.WireID()], t, &coeffBetaTau1[i])
		}
		// B
		for _, t := range c.R {
			accumulateG1(&evals.G1.B[t.WireID()], t, &coeffTau1[i])
			accumulateG2(&evals.G2.B[t.WireID()], t, &coeffTau2[i])
			accumulateG1(&aB[t.WireID()], t, &coeffAlphaTau1[i])
		}
		// C
		for _, t := range c.O {
			accumulateG1(&C[t.WireID()], t, &coeffTau1[i])
		}
		i++
	}

	// Prepare default contribution
	_, _, g1, g2 := curve.Generators()
	p.Parameters.G1.Delta = g1
	p.Parameters.G2.Delta = g2

	// Build Z in PK as Ï„â±(Ï„â¿ - 1)  = Ï„â½â±âºâ¿â¾ - Ï„â±  for i âˆˆ [0, n-2]
	// Ï„â±(Ï„â¿ - 1)  = Ï„â½â±âºâ¿â¾ - Ï„â±  for i âˆˆ [0, n-2]
	n := len(commons.G1.AlphaTau)
	p.Parameters.G1.Z = make([]curve.G1Affine, n)
	for i := 0; i < n-1; i++ { // TODO @Tabaie why is the last element always 0?
		p.Parameters.G1.Z[i].Sub(&commons.G1.Tau[i+n], &commons.G1.Tau[i])
	}
	bitReverse(p.Parameters.G1.Z)
	p.Parameters.G1.Z = p.Parameters.G1.Z[:n-1]

	commitments := r1cs.CommitmentInfo.(constraint.Groth16Commitments)

	evals.G1.CKK = make([][]curve.G1Affine, len(commitments))
	p.Sigmas = make([]valueUpdate, len(commitments))
	p.Parameters.G1.SigmaCKK = make([][]curve.G1Affine, len(commitments))
	p.Parameters.G2.Sigma = make([]curve.G2Affine, len(commitments))

	for j := range commitments {
		evals.G1.CKK[j] = make([]curve.G1Affine, 0, len(commitments[j].PrivateCommitted))
		p.Parameters.G2.Sigma[j] = g2
	}

	nbCommitted := internal.NbElements(commitments.GetPrivateCommitted())

	// Evaluate PKK

	p.Parameters.G1.PKK = make([]curve.G1Affine, 0, nbInternal+nbSecret-nbCommitted-len(commitments))
	evals.G1.VKK = make([]curve.G1Affine, 0, nbPublic+len(commitments))
	committedIterator := internal.NewMergeIterator(commitments.GetPrivateCommitted())
	nbCommitmentsSeen := 0
	for j := 0; j < nWires; j++ {
		// since as yet Î´, Î³ = 1, the VKK and PKK are computed identically, as Î²A + Î±B + C
		var tmp curve.G1Affine
		tmp.Add(&bA[j], &aB[j])
		tmp.Add(&tmp, &C[j])
		commitmentIndex := committedIterator.IndexIfNext(j)
		isCommitment := nbCommitmentsSeen < len(commitments) && commitments[nbCommitmentsSeen].CommitmentIndex == j
		if commitmentIndex != -1 {
			evals.G1.CKK[commitmentIndex] = append(evals.G1.CKK[commitmentIndex], tmp)
		} else if j < nbPublic || isCommitment {
			evals.G1.VKK = append(evals.G1.VKK, tmp)
		} else {
			p.Parameters.G1.PKK = append(p.Parameters.G1.PKK, tmp)
		}
		if isCommitment {
			nbCommitmentsSeen++
		}
	}

	for j := range commitments {
		p.Parameters.G1.SigmaCKK[j] = slices.Clone(evals.G1.CKK[j])
	}

	p.Challenge = nil

	return evals
}

// VerifyPhase2 for circuit described by r1cs
// using parameters from commons
// beaconChallenge is the output of the random beacon
// and c are the output from the contributors
// WARNING: the last contribution object will be modified
func VerifyPhase2(r1cs *cs.R1CS, commons *SrsCommons, beaconChallenge []byte, c ...*Phase2) (groth16.ProvingKey, groth16.VerifyingKey, error) {
	prev := new(Phase2)
	evals := prev.Initialize(r1cs, commons)
	for i := range c {
		if err := prev.Verify(c[i]); err != nil {
			return nil, nil, err
		}
		prev = c[i]
	}

	pk, vk := prev.Seal(commons, &evals, beaconChallenge)
	return pk, vk, nil
}

func (p *Phase2) hash() []byte {
	sha := sha256.New()
	p.WriteTo(sha)
	return sha.Sum(nil)
}

func cloneAppend(s ...[]curve.G1Affine) []curve.G1Affine {
	l := 0
	for _, s := range s {
		l += len(s)
	}
	res := make([]curve.G1Affine, 0, l)
	for _, s := range s {
		res = append(res, s...)
	}
	return res
}
