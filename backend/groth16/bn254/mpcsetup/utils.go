// Copyright 2020-2024 Consensys Software Inc.
// Licensed under the Apache License, Version 2.0. See the LICENSE file for details.

// Code generated by gnark DO NOT EDIT

package mpcsetup

import (
	"bytes"
	"errors"
	"github.com/consensys/gnark-crypto/ecc"
	curve "github.com/consensys/gnark-crypto/ecc/bn254"
	"github.com/consensys/gnark-crypto/ecc/bn254/fr"
	"github.com/consensys/gnark/internal/utils"
	"github.com/consensys/gnark/internal/utils/test_utils"
	"math/big"
	"math/bits"
	"runtime"
)

func bitReverse[T any](a []T) {
	n := uint64(len(a))
	nn := uint64(64 - bits.TrailingZeros64(n))

	for i := uint64(0); i < n; i++ {
		irev := bits.Reverse64(i) >> nn
		if irev > i {
			a[i], a[irev] = a[irev], a[i]
		}
	}
}

func linearCombCoeffs(n int) []fr.Element {
	return bivariateRandomMonomials(n)
}

// Returns [1, a, a¬≤, ..., a·¥∫‚Åª¬π ]
func powers(a *fr.Element, n int) []fr.Element {

	result := make([]fr.Element, n)
	if n >= 1 {
		result[0].SetOne()
	}
	if n >= 2 {
		result[1].Set(a)
	}
	for i := 2; i < n; i++ {
		result[i].Mul(&result[i-1], a)
	}
	return result
}

// Returns [a·µ¢A·µ¢, ...]‚ààùîæ‚ÇÅ
// it assumes len(A) ‚â§ len(a)
func scaleG1InPlace(A []curve.G1Affine, a []fr.Element) {
	/*if a[0].IsOne() {
		A = A[1:]
		a = a[1:]
	}*/
	utils.Parallelize(len(A), func(start, end int) {
		var tmp big.Int
		for i := start; i < end; i++ {
			a[i].BigInt(&tmp)
			A[i].ScalarMultiplication(&A[i], &tmp)
		}
	})
}

// Returns [a·µ¢A·µ¢, ...]‚ààùîæ‚ÇÇ
// it assumes len(A) ‚â§ len(a)
func scaleG2InPlace(A []curve.G2Affine, a []fr.Element) {
	/*if a[0].IsOne() {
		A = A[1:]
		a = a[1:]
	}*/
	utils.Parallelize(len(A), func(start, end int) {
		var tmp big.Int
		for i := start; i < end; i++ {
			a[i].BigInt(&tmp)
			A[i].ScalarMultiplication(&A[i], &tmp)
		}
	})
}

// Check n‚ÇÅ/d‚ÇÅ = n‚ÇÇ/d‚ÇÇ i.e. e(n‚ÇÅ, d‚ÇÇ) = e(d‚ÇÅ, n‚ÇÇ). No subgroup checks.
func sameRatioUnsafe(n1, d1 curve.G1Affine, n2, d2 curve.G2Affine) bool {
	var nd1 curve.G1Affine
	nd1.Neg(&d1)
	res, err := curve.PairingCheck(
		[]curve.G1Affine{n1, nd1},
		[]curve.G2Affine{d2, n2})
	if err != nil {
		panic(err)
	}
	return res
}

// returns ‚àë r·µ¢A·µ¢
func linearCombination(A []curve.G1Affine, r []fr.Element) curve.G1Affine {
	nc := runtime.NumCPU()
	var res curve.G1Affine
	if _, err := res.MultiExp(A, r[:len(A)], ecc.MultiExpConfig{NbTasks: nc}); err != nil {
		panic(err)
	}
	return res
}

// linearCombinationsG1 returns
//
//		powers[0].A[0] + powers[1].A[1] + ... + powers[ends[0]-2].A[ends[0]-2]
//	  + powers[ends[0]].A[ends[0]] + ... + powers[ends[1]-2].A[ends[1]-2]
//	    ....       (truncated)
//
//		powers[0].A[1] + powers[1].A[2] + ... + powers[ends[0]-2].A[ends[0]-1]
//	  + powers[ends[0]].A[ends[0]+1]  + ... + powers[ends[1]-2].A[ends[1]-1]
//	    ....       (shifted)
//
// It is assumed without checking that powers[i+1] = powers[i]*powers[1] unless i+1 is a partial sum of sizes
// the slices powers and A will be modified
func linearCombinationsG1(A []curve.G1Affine, powers []fr.Element, ends []int) (truncated, shifted curve.G1Affine) {
	if ends[len(ends)-1] != len(A) || len(A) != len(powers) {
		panic("lengths mismatch")
	}

	largeCoeffs := make([]fr.Element, len(ends))
	for i := range ends {
		largeCoeffs[i].Neg(&powers[ends[i]-1])
		powers[ends[i]-1].SetZero()
	}

	msmCfg := ecc.MultiExpConfig{NbTasks: runtime.NumCPU()}

	if _, err := shifted.MultiExp(A, powers, msmCfg); err != nil {
		panic(err)
	}

	// compute truncated as
	//                r.shifted
	//              + powers[0].A[0] + powers[ends[0].A[ends[0]] + ...
	//              - powers[ends[0]-1].A[ends[0]-1] - powers[ends[1]-1].A[ends[1]-1] - ...
	r := powers[1]
	prevEnd := 0
	for i := range ends {
		if ends[i] <= prevEnd {
			panic("non-increasing ends")
		}

		powers[2*i] = powers[prevEnd]
		powers[2*i+1] = largeCoeffs[i]

		A[2*i] = A[prevEnd]
		A[2*i+1] = A[ends[i]-1]

		prevEnd = ends[i]
	}
	powers[len(ends)*2] = r
	A[len(ends)*2] = shifted

	// TODO @Tabaie O(1) MSM worth it?
	if _, err := truncated.MultiExp(A[:2*len(ends)+1], powers[:2*len(ends)+1], msmCfg); err != nil {
		panic(err)
	}

	return
}

// linearCombinationsG2 assumes, and does not check, that rPowers[i+1] = rPowers[1].rPowers[i] for all applicable i
// Also assumed that 3 ‚â§ N ‚âî len(A) ‚â§ len(rPowers)
// the results are truncated = ‚àë_{i=0}^{N-2} r‚Å±A·µ¢, shifted = ‚àë_{i=1}^{N-1} r‚Å±A·µ¢
func linearCombinationsG2(A []curve.G2Affine, rPowers []fr.Element) (truncated, shifted curve.G2Affine) {
	// the common section, 1 to N-2
	var common curve.G2Affine
	if _, err := common.MultiExp(A[1:len(A)-1], rPowers[:len(A)-2], ecc.MultiExpConfig{NbTasks: runtime.NumCPU()}); err != nil { // A[1] + r.A[2] + ... + r·¥∫‚Åª¬≥.A[N-2]
		panic(err)
	}
	var c big.Int
	rPowers[1].BigInt(&c)
	truncated.ScalarMultiplication(&common, &c).Add(&truncated, &A[0]) // A[0] + r.A[1] + r¬≤.A[2] + ... + r·¥∫‚Åª¬≤.A[N-2]

	rPowers[len(A)-1].BigInt(&c)
	shifted.ScalarMultiplication(&A[len(A)-1], &c).Add(&shifted, &common)

	return
}

// Generate R‚ààùîæ‚ÇÇ as Hash(gÀ¢, gÀ¢À£, challenge, dst)
// it is to be used as a challenge for generating a proof of knowledge to x
// œÄ ‚âî x.r; e([1]‚ÇÅ, œÄ) =Ôπñ e([x]‚ÇÅ, r)
func genR(sG1 curve.G1Affine, challenge []byte, dst byte) curve.G2Affine {
	var buf bytes.Buffer
	buf.Grow(len(challenge) + curve.SizeOfG1AffineUncompressed*2)
	buf.Write(sG1.Marshal())
	buf.Write(challenge)
	spG2, err := curve.HashToG2(buf.Bytes(), []byte{dst})
	if err != nil {
		panic(err)
	}
	return spG2
}

type pair struct {
	g1 curve.G1Affine
	g2 *curve.G2Affine // optional; some values expect to have a ùîæ‚ÇÇ representation, some don't.
}

// check that g1, g2 are valid as updated values, i.e. in their subgroups, and non-zero
func (p *pair) validUpdate() bool {
	// if the contribution is 0 the product is doomed to be 0.
	// no need to check this for g2 independently because if g1 is 0 and g2 is not, consistency checks will fail
	return !p.g1.IsInfinity() && p.g1.IsInSubGroup() && (p.g2 == nil || p.g2.IsInSubGroup())
}

type valueUpdate struct {
	contributionCommitment curve.G1Affine // x or [X‚±º]‚ÇÅ
	contributionPok        curve.G2Affine // œÄ ‚âî x.r ‚àà ùîæ‚ÇÇ
}

// updateValue produces values associated with contribution to an existing value.
// the second output is toxic waste. It is the caller's responsibility to safely "dispose" of it.
func updateValue(value curve.G1Affine, challenge []byte, dst byte) (proof valueUpdate, contributionValue fr.Element) {
	if _, err := contributionValue.SetRandom(); err != nil {
		panic(err)
	}
	var contributionValueI big.Int
	contributionValue.BigInt(&contributionValueI)

	_, _, g1, _ := curve.Generators()
	proof.contributionCommitment.ScalarMultiplication(&g1, &contributionValueI)
	value.ScalarMultiplication(&value, &contributionValueI)

	// proof of knowledge to commitment. Algorithm 3 from section 3.7
	pokBase := genR(proof.contributionCommitment, challenge, dst) // r
	test_utils.ConditionalLog("pok base", pokBase.String())
	proof.contributionPok.ScalarMultiplication(&pokBase, &contributionValueI)

	return
}

// verify corresponds with verification steps {i, i+3} with 1 ‚â§ i ‚â§ 3 in section 7.1 of Bowe-Gabizon17
// it checks the proof of knowledge of the contribution, and the fact that the product of the contribution
// and previous commitment makes the new commitment.
// prevCommitment is assumed to be valid. No subgroup check and the like.
func (x *valueUpdate) verify(denom, num pair, challenge []byte, dst byte) error {
	noG2 := denom.g2 == nil
	if noG2 != (num.g2 == nil) {
		return errors.New("erasing or creating g2 values")
	}

	if !x.contributionPok.IsInSubGroup() || !x.contributionCommitment.IsInSubGroup() || !num.validUpdate() {
		return errors.New("contribution values subgroup check failed")
	}

	// verify commitment proof of knowledge. CheckPOK, algorithm 4 from section 3.7
	r := genR(x.contributionCommitment, challenge, dst) // verification challenge in the form of a g2 base
	_, _, g1, _ := curve.Generators()
	if !sameRatioUnsafe(x.contributionCommitment, g1, x.contributionPok, r) { // œÄ =? x.r i.e. x/g1 =? œÄ/r
		return errors.New("contribution proof of knowledge verification failed")
	}

	// check that the num/denom ratio is consistent between the ùîæ‚ÇÅ and ùîæ‚ÇÇ representations. Based on CONSISTENT, algorithm 2 in Section 3.6.
	if !noG2 && !sameRatioUnsafe(num.g1, denom.g1, *num.g2, *denom.g2) {
		return errors.New("g2 update inconsistent")
	}

	// now verify that num‚ÇÅ/denom‚ÇÅ = x ( = x/g1 = œÄ/r )
	// have to use the latter value for the RHS because we sameRatio needs both ùîæ‚ÇÅ and ùîæ‚ÇÇ values
	if !sameRatioUnsafe(num.g1, denom.g1, x.contributionPok, r) {
		return errors.New("g1 update inconsistent")
	}

	return nil
}

func toRefs[T any](s []T) []*T {
	res := make([]*T, len(s))
	for i := range s {
		res[i] = &s[i]
	}
	return res
}

func areInSubGroup[T interface{ IsInSubGroup() bool }](s []T) bool {
	for i := range s {
		if !s[i].IsInSubGroup() {
			return false
		}
	}
	return true
}

func areInSubGroupG1(s []curve.G1Affine) bool {
	return areInSubGroup(toRefs(s))
}

func areInSubGroupG2(s []curve.G2Affine) bool {
	return areInSubGroup(toRefs(s))
}

// bivariateRandomMonomials returns 1, x, ..., x^{ends[0]-1}; y, xy, ..., x^{ends[1]-ends[0]-1}y; ...
// all concatenated in the same slice
func bivariateRandomMonomials(ends ...int) []fr.Element {
	if len(ends) == 0 {
		return nil
	}

	res := make([]fr.Element, ends[len(ends)-1])
	if _, err := res[1].SetRandom(); err != nil {
		panic(err)
	}
	setPowers(res[:ends[0]])

	if len(ends) == 1 {
		return res
	}

	y := make([]fr.Element, len(ends))
	if _, err := y[1].SetRandom(); err != nil {
		panic(err)
	}
	setPowers(y)

	for d := 1; d < len(ends); d++ {
		xdeg := ends[d] - ends[d-1]
		if xdeg > ends[0] {
			panic("impl detail: first maximum degree for x must be the greatest")
		}

		for i := range xdeg {
			res[ends[d-1]+i].Mul(&res[i], &y[d])
		}
	}

	return res
}

// sets x[i] = x[1]‚Å±
func setPowers(x []fr.Element) {
	if len(x) == 0 {
		return
	}
	x[0].SetOne()
	for i := 2; i < len(x); i++ {
		x[i].Mul(&x[i-1], &x[1])
	}
}

func partialSums(s ...int) []int {
	if len(s) == 0 {
		return nil
	}
	sums := make([]int, len(s))
	sums[0] = s[0]
	for i := 1; i < len(s); i++ {
		sums[i] = sums[i-1] + s[i]
	}
	return sums
}

func beaconContributions(hash, beaconChallenge []byte, n int) []fr.Element {
	var (
		bb  bytes.Buffer
		err error
	)
	bb.Grow(len(hash) + len(beaconChallenge))
	bb.Write(hash)
	bb.Write(beaconChallenge)

	res := make([]fr.Element, 1)

	allNonZero := func() bool {
		for i := range res {
			if res[i].IsZero() {
				return false
			}
		}
		return true
	}

	// cryptographically unlikely for this to be run more than once
	for !allNonZero() {
		if res, err = fr.Hash(bb.Bytes(), []byte("Groth16 SRS generation ceremony - Phase 1 Final Step"), n); err != nil {
			panic(err)
		}
		bb.WriteByte('=') // padding just so that the hash is different next time
	}

	return res
}
