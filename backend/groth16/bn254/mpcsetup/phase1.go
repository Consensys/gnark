// Copyright 2020-2024 Consensys Software Inc.
// Licensed under the Apache License, Version 2.0. See the LICENSE file for details.

// Code generated by gnark DO NOT EDIT

package mpcsetup

import (
	"bytes"
	"crypto/sha256"
	"errors"
	"fmt"
	curve "github.com/consensys/gnark-crypto/ecc/bn254"
	"github.com/consensys/gnark-crypto/ecc/bn254/fr"
	"math/big"
)

// SrsCommons are the circuit-independent components of the Groth16 SRS,
// computed by the first phase.
// in all that follows, N is the domain size
type SrsCommons struct {
	G1 struct {
		Tau      []curve.G1Affine // {[τ⁰]₁, [τ¹]₁, [τ²]₁, …, [τ²ᴺ⁻²]₁}
		AlphaTau []curve.G1Affine // {α[τ⁰]₁, α[τ¹]₁, α[τ²]₁, …, α[τᴺ⁻¹]₁}
		BetaTau  []curve.G1Affine // {β[τ⁰]₁, β[τ¹]₁, β[τ²]₁, …, β[τᴺ⁻¹]₁}
	}
	G2 struct {
		Tau  []curve.G2Affine // {[τ⁰]₂, [τ¹]₂, [τ²]₂, …, [τᴺ⁻¹]₂}
		Beta curve.G2Affine   // [β]₂
	}
}

// Phase1 in line with Phase1 of the MPC described in
// https://eprint.iacr.org/2017/1050.pdf
//
// Also known as "Powers of Tau"
type Phase1 struct {
	proofs struct { // "main" contributions
		Tau, Alpha, Beta valueUpdate
	}
	parameters SrsCommons
	Challenge  []byte // Hash of the transcript PRIOR to this participant
}

// Contribute contributes randomness to the Phase1 object. This mutates Phase1.
// p is trusted to be well-formed. The ReadFrom function performs such basic sanity checks.
func (p *Phase1) Contribute() {
	p.Challenge = p.hash()

	// Generate main value updates
	var (
		tauContrib, alphaContrib, betaContrib fr.Element
	)
	p.proofs.Tau, tauContrib = updateValue(&p.parameters.G1.Tau[1], p.Challenge, 1)
	p.proofs.Alpha, alphaContrib = updateValue(&p.parameters.G1.AlphaTau[0], p.Challenge, 2)
	p.proofs.Beta, betaContrib = updateValue(&p.parameters.G1.BetaTau[0], p.Challenge, 3)

	p.parameters.update(&tauContrib, &alphaContrib, &betaContrib, true)
}

// setZero instantiates the parameters, and sets all contributions to zero
func (c *SrsCommons) setZero(N uint64) {
	c.G1.Tau = make([]curve.G1Affine, 2*N-2)
	c.G2.Tau = make([]curve.G2Affine, N)
	c.G1.AlphaTau = make([]curve.G1Affine, N)
	c.G1.BetaTau = make([]curve.G1Affine, N)
	_, _, c.G1.Tau[0], c.G2.Tau[0] = curve.Generators()
}

// setOne instantiates the parameters, and sets all contributions to one
func (c *SrsCommons) setOne(N uint64) {
	c.setZero(N)
	for i := range c.G1.Tau {
		c.G1.Tau[i] = c.G1.Tau[0]
	}
	for i := range c.G1.AlphaTau {
		c.G1.AlphaTau[i] = c.G1.AlphaTau[0]
		c.G1.BetaTau[i] = c.G1.AlphaTau[0]
		c.G2.Tau[i] = c.G2.Tau[0]
	}
	c.G2.Beta = c.G2.Tau[0]
}

// from the fourth argument on this just gives an opportunity to avoid recomputing some scalar multiplications
func (c *SrsCommons) update(tauUpdate, alphaUpdate, betaUpdate *fr.Element, principalG1sPrecomputed bool) {
	i0 := 0
	if principalG1sPrecomputed {
		i0 = 1
	}

	// TODO @gbotrel working with jacobian points here will help with perf.

	tauUpdates := powers(tauUpdate, len(c.G1.Tau))
	// saving 3 exactly scalar muls among millions. Not a significant gain but might as well.
	scaleG1InPlace(c.G1.Tau[i0+1:], tauUpdates[i0+1:]) // first element remains 1. second element may have been precomputed.
	scaleG2InPlace(c.G2.Tau[1:], tauUpdates[1:])

	alphaUpdates := make([]fr.Element, len(c.G1.AlphaTau))
	alphaUpdates[0].Set(alphaUpdate)
	for i := i0; i < len(alphaUpdates); i++ {
		alphaUpdates[i].Mul(&tauUpdates[i], &alphaUpdates[1])
	}
	scaleG1InPlace(c.G1.AlphaTau[i0:], alphaUpdates[i0:]) // first element may have been precomputed

	betaUpdates := make([]fr.Element, len(c.G1.BetaTau))
	betaUpdates[0].Set(betaUpdate)
	for i := i0; i < len(betaUpdates); i++ {
		alphaUpdates[i].Mul(&tauUpdates[i], &betaUpdates[1])
	}
	scaleG1InPlace(c.G1.BetaTau[i0:], betaUpdates[i0:])

	var betaUpdateI big.Int
	betaUpdate.SetBigInt(&betaUpdateI)
	c.G2.Beta.ScalarMultiplication(&c.G2.Beta, &betaUpdateI)
}

// Seal performs the final contribution and outputs the final parameters.
// No randomization is performed at this step.
// A verifier should simply re-run this and check
// that it produces the same values.
// The inner workings of the random beacon are out of scope.
// WARNING: Seal modifies p, just as Contribute does.
// The result will be an INVALID Phase1 object, since no proof of correctness is produced.
func (p *Phase1) Seal(beaconChallenge []byte) SrsCommons {
	var (
		bb  bytes.Buffer
		err error
	)
	bb.Write(p.hash())
	bb.Write(beaconChallenge)

	newContribs := make([]fr.Element, 3)
	// cryptographically unlikely for this to be run more than once
	for newContribs[0].IsZero() || newContribs[1].IsZero() || newContribs[2].IsZero() {
		if newContribs, err = fr.Hash(bb.Bytes(), []byte("Groth16 SRS generation ceremony - Phase 1 Final Step"), 3); err != nil {
			panic(err)
		}
		bb.WriteByte('=') // padding just so that the hash is different next time
	}

	p.parameters.update(&newContribs[0], &newContribs[1], &newContribs[2], false)

	return p.parameters
}

func VerifyPhase1(c0, c1 *Phase1, c ...*Phase1) error {
	contribs := append([]*Phase1{c0, c1}, c...)
	for i := 0; i < len(contribs)-1; i++ {
		if err := contribs[i].Verify(contribs[i+1]); err != nil {
			return err
		}
	}
	return nil
}

// Verify assumes previous is correct
func (p *Phase1) Verify(next *Phase1) error {

	challenge := p.hash()
	if len(next.Challenge) != 0 && !bytes.Equal(next.Challenge, challenge) {
		return errors.New("the challenge does not match the previous phase's hash")
	}
	next.Challenge = challenge

	// the internal consistency of the vector sizes in next is assumed
	// so is its well-formedness i.e. Tau[0] = 1
	// it remains to check it is consistent with p
	N := len(next.parameters.G2.Tau)
	if N != len(p.parameters.G2.Tau) {
		return errors.New("domain size mismatch")
	}

	r := linearCombCoeffs(len(next.parameters.G1.Tau) + len(next.parameters.G1.AlphaTau) + len(next.parameters.G1.BetaTau) - 1) // the longest of all lengths
	// will be reusing the coefficients

	// verify updates to τ, α, β
	if err := next.proofs.Tau.verify(pair{p.parameters.G1.Tau[1], nil}, pair{next.parameters.G1.Tau[1], nil}, challenge, 1); err != nil {
		return fmt.Errorf("failed to verify contribution to τ: %w", err)
	}
	if err := next.proofs.Alpha.verify(pair{p.parameters.G1.AlphaTau[0], nil}, pair{p.parameters.G1.AlphaTau[0], nil}, challenge, 2); err != nil {
		return fmt.Errorf("failed to verify contribution to α: %w", err)
	}
	if err := next.proofs.Beta.verify(pair{p.parameters.G1.BetaTau[0], &p.parameters.G2.Beta}, pair{next.parameters.G1.BetaTau[0], &next.parameters.G2.Beta}, challenge, 3); err != nil {
		return fmt.Errorf("failed to verify contribution to β: %w", err)
	}

	if !areInSubGroupG1(next.parameters.G1.Tau[2:]) || !areInSubGroupG1(next.parameters.G1.BetaTau[1:]) || !areInSubGroupG1(next.parameters.G1.AlphaTau[1:]) {
		return errors.New("derived values 𝔾₁ subgroup check failed")
	}
	if !areInSubGroupG2(next.parameters.G2.Tau[2:]) {
		return errors.New("derived values 𝔾₂ subgroup check failed")
	}

	_, _, g1, g2 := curve.Generators()

	// lemma: let R be an integral domain and
	// F = ∑ fᵢⱼ XⁱYʲ     F' = ∑ f'ᵢⱼ XⁱYʲ
	// G = ∑ gᵢⱼ ZⁱTʲ     G' = ∑ g'ᵢⱼ ZⁱTʲ
	// polynomials in R[X,Y,Z,T].
	// if F/F' = G/G'
	// then F/F' = G/G' ∈ FracR
	//
	// view our polynomials in FracR[X,Y,Z,T]
	// By multiplying out the polynomials we get
	// FG' = F'G ⇒ ∑ fᵢⱼg'ₖₗ XᶦYʲZᵏTˡ = ∑ f'ᵢⱼgₖₗ XᶦYʲZᵏTˡ
	// pick i0 ,j0 , k0, l0 where f'ᵢ₀ⱼ₀, g'ₖ₀ₗ₀ ≠ 0
	// let x ≔ fᵢ₀ⱼ₀/f'ᵢ₀ⱼ₀ = gₖ₀ₗ₀/g'ₖ₀ₗ₀
	// now for any i,j: fᵢⱼg'ₖ₀ₗ₀ = f'ᵢⱼgₖ₀ₗ₀ ⇒
	// fᵢⱼ = x f'ᵢⱼ
	// likewise for any i,j: fᵢ₀ⱼ₀g'ᵢⱼ = f'ᵢ₀ⱼ₀gᵢⱼ ⇒
	// gᵢⱼ = x g'ᵢⱼ

	// now we use this to check that:
	//    1. aᵢ ≔ G1.Tau[i]      = [τⁱ]₁
	//    2. bᵢ ≔ G2.Tau[i]      = [τⁱ]₂
	//    3. cᵢ ≔ G1.AlphaTau[i] = [ατⁱ]₁
	//    4. dᵢ ≔ G1.BetaTau[i]  = [βτⁱ]₁

	//
	// we already know that a₀ = 1, a₁ = τ,
	// c₀ = α, d₀ = β, b₀ = 1,
	// construct the polynomials
	// F  ≔ a₀ + a₁X + ... + a₂ₙ₋₃X²ᴺ⁻³ + c₀Y + c₁XY + ... + cₙ₋₂Xᴺ⁻²Y + d₀Y² + d₁XY² + ... + dₙ₋₂Xᴺ⁻²Y²
	// F' ≔ a₁ + a₂X + ... + a₂ₙ₋₂X²ᴺ⁻³ + c₁Y + c₂XY + ... + cₙ₋₁Xᴺ⁻²Y + d₁Y² + d₂XY² + ... + dₙ₋₁Xᴺ⁻²Y²
	// G  ≔ b

	// we want to establish G1.AlphaTau[i] = [ατⁱ]₁,
	// already known for i = 0 from the contribution checks
	// let [cᵢ]₁ = G1.AlphaTau[i]
	// let C1 ≔ c₀ + rc₁ + ... + rᴺ⁻²cₙ₋₂
	//     C2 ≔ c₁ + rc₂ + ... + rᴺ⁻²cₙ₋₁
	// then if indeed cᵢ = ατⁱ, we get
	// C1/C2 = 1/τ
	// conversely, from C1/C2 = 1/τ we get
	// c₁ + rc₂ + ... + rᴺ⁻²cₙ₋₁ = τc₀ + rτc₁ + ... + rᴺ⁻²τcₙ₋₂
	// which by the Schwartz-Zippel lemma and a simple induction
	// implies the desired result with overwhelming probability.

	// The same argument works for G1.BetaTau[i]

	// we also want to establish Gⱼ.Tau[i] = [τⁱ]ⱼ
	// let [aᵢ]₁ = G1.Tau[i] and [bᵢ]₂ = G2.Tau[i]
	// let A1 ≔ a₀ + ra₁ + ... + r²ᴺ⁻³a₂ₙ₋₃
	//     A2 ≔ a₁ + ra₂ + ... + r²ᴺ⁻³a₂ₙ₋₂
	//     B1 ≔ b₀ + sb₁ + ... + sᴺ⁻²bₙ₋₂
	//     B2 ≔ b₁ + sb₂ + ... + sᴺ⁻²bₙ₋₁
	//  for random r,s
	// if the values are correct clearly we get A1/A2 = B1/B2
	//
	// if A1/A2 = B1/B2, by the bivariate Schwartz-Zippel we get
	// (a₀ + a₁X + ... + a₂ₙ₋₃X²ᴺ⁻³)(b₁ + b₂Y + ... + bₙ₋₁Yᴺ⁻²) =
	// (a₁ + a₂X + ... + a₂ₙ₋₂X²ᴺ⁻³)(b₀ + b₁Y + ... + bₙ₋₂Yᴺ⁻²)
	// furthermore by previous checks we already know that
	// a₀=1, a₁= τ
	// Assume by induction that for all i < m ≤ N-1: bᵢ = τⁱ
	// Then modulo (X, Yᵐ) we get
	// τ + τ²Y + ... + τᵐ⁻¹Yᵐ⁻² + bₘYᵐ⁻¹ =
	// τ (1 + τ²Y + ... + τᵐ⁻¹Yᵐ⁻¹)
	// which gives bₘ = τᵐ
	// We then get A1/A2 = 1/τ which by the previous lemma gives
	// aᵢ = τⁱ

	// now to combine all the above

	// verify monomials

	// for 1 ≤ i ≤ 2N-3 we want to check τⁱ⁺¹/τⁱ = τ
	// i.e. e(τⁱ⁺¹,[1]₂) = e(τⁱ,[τ]₂). Due to bi-linearity we can instead check
	// e(∑rⁱ⁻¹τⁱ⁺¹,[1]₂) = e(∑rⁱ⁻¹τⁱ,[τ]₂), which is tantamount to the check
	// ∑rⁱ⁻¹τⁱ⁺¹ / ∑rⁱ⁻¹τⁱ = τ

	tauT1, tauS1 := linearCombinationsG1(next.parameters.G1.Tau[1:], r)
	tauT2, tauS2 := linearCombinationsG2(next.parameters.G2.Tau[1:], r)

	if !sameRatioUnsafe(tauS1, tauT1, next.parameters.G2.Tau[1], g2) {
		return errors.New("couldn't verify 𝔾₁ representations of the τⁱ")
	}

	if !sameRatioUnsafe(next.parameters.G1.Tau[1], g1, tauS2, tauT2) {
		return errors.New("couldn't verify 𝔾₂ representations of the τⁱ")
	}

	alphaTT, alphaTS := linearCombinationsG1(next.parameters.G1.AlphaTau, r)
	betaTT, betaTS := linearCombinationsG1(next.parameters.G1.BetaTau, r)

	// for 0 ≤ i < N we want to check the ατⁱ
	// By well-formedness checked by ReadFrom, we assume that ατ⁰ = α
	// For 0 < i < N we check that ατⁱ/ατⁱ⁻¹ = τ, since we have a representation of τ in 𝔾₂
	// with a similar bi-linearity argument as above we can do this with a single pairing check

	// TODO eliminate these by combining with update checking

	if !sameRatioUnsafe(alphaTS, alphaTT, next.parameters.G2.Tau[1], g2) {
		return errors.New("couldn't verify the ατⁱ")
	}
	if !sameRatioUnsafe(betaTS, betaTT, next.parameters.G2.Tau[1], g2) {
		return errors.New("couldn't verify the βτⁱ")
	}

	// TODO @Tabaie combine all pairing checks except the second one

	taus := linearCombination(next.parameters.G1.Tau[:N], r)       // 1 + r.τ¹ + r.τ² + … + rᴺ⁻¹.τᴺ⁻¹
	alphaTaus := linearCombination(next.parameters.G1.AlphaTau, r) // α + r.ατ¹ + r.ατ² + … + rᴺ⁻¹.ατᴺ⁻¹
	betaTaus := linearCombination(next.parameters.G1.BetaTau, r)   // β + r.τ¹ + r.βτ² + … + rᴺ⁻¹.βτᴺ⁻¹

	return nil
}

func (p *Phase1) hash() []byte {
	if len(p.Challenge) == 0 {
		panic("challenge field missing")
	}
	sha := sha256.New()
	p.WriteTo(sha)
	sha.Write(p.Challenge)
	return sha.Sum(nil)
}
